По заданию написан алгоритм для построения линейной регресии на данных boston data set.json.
Попытался подобрать оптимальный вектор W для ошибки MSE с L2 регуляризацией и нарисовал результат на одном графике с данными и с типовой реализацией от sklearn
Для подбора угла наклона прямой градиентного спуска,  вычислил значения градиентов для функции ошибок типа MSE и MAE с L2 и L1
регуляризацией

На графике мы видим, что прямые для рукописного алгоритма поиска w и sklearn очень близки, но не совпадают полностью.
Это получилось из-за того что:
1) Наш алгоритм не имеет байес предсказаний
2) у нас разные веса штрафов